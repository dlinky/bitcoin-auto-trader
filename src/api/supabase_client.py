#!/usr/bin/env python3
"""
Supabase í´ë¼ì´ì–¸íŠ¸ ëª¨ë“ˆ (datetime ì§ë ¬í™” ì˜¤ë¥˜ ìˆ˜ì •)
íŒŒì¼ ìœ„ì¹˜: src/api/supabase_client.py
"""

import os
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from pathlib import Path
from supabase import create_client, Client
import pandas as pd

logger = logging.getLogger(__name__)

class SupabaseClient:
    """Supabase ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, url: Optional[str] = None, key: Optional[str] = None):
        """
        Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        
        Args:
            url: Supabase í”„ë¡œì íŠ¸ URL
            key: Supabase anon key
        """
        self.url = url or os.getenv('SUPABASE_URL')
        self.key = key or os.getenv('SUPABASE_KEY')
        
        if not self.url or not self.key:
            raise ValueError("SUPABASE_URLê³¼ SUPABASE_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        self.client: Client = create_client(self.url, self.key)
        
        # ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦
        if not self._validate_database():
            raise Exception("ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦ ì‹¤íŒ¨. ìŠ¤í‚¤ë§ˆë¥¼ í™•ì¸í•˜ê±°ë‚˜ ìƒì„±í•˜ì„¸ìš”.")
        
        logger.info("Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _datetime_to_string(self, dt: datetime) -> str:
        """datetime ê°ì²´ë¥¼ ISO ë¬¸ìì—´ë¡œ ë³€í™˜"""
        if isinstance(dt, datetime):
            return dt.isoformat()
        return dt
    
    def _validate_database(self) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ê²€ì¦"""
        try:
            logger.info("ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ê²€ì¦ ì‹œì‘")
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            if not self._test_connection():
                logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
                return False
            
            # í•„ìˆ˜ í…Œì´ë¸” í™•ì¸
            required_tables = ['strategies', 'traders', 'positions', 'trades', 'market_data', 'system_logs']
            missing_tables = []
            
            for table in required_tables:
                if not self._check_table_exists(table):
                    missing_tables.append(table)
            
            if missing_tables:
                logger.warning(f"ëˆ„ë½ëœ í…Œì´ë¸”: {missing_tables}")
                self._suggest_schema_creation(missing_tables)
                return False
            
            # system_logsì˜ module_name ì»¬ëŸ¼ í™•ì¸
            if not self._check_column_exists('system_logs', 'module_name'):
                logger.warning("system_logs í…Œì´ë¸”ì— module_name ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤")
                self._suggest_schema_update()
                return False
            
            logger.info("ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ê²€ì¦ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦ ì¤‘ ì—ëŸ¬: {e}")
            return False
    
    def _test_connection(self) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            response = self.client.table('strategies').select('id').limit(1).execute()
            return True
        except Exception as e:
            logger.error(f"ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def _check_table_exists(self, table_name: str) -> bool:
        """í…Œì´ë¸” ì¡´ì¬ í™•ì¸"""
        try:
            response = self.client.table(table_name).select('*').limit(1).execute()
            return True
        except Exception:
            return False
    
    def _check_column_exists(self, table_name: str, column_name: str) -> bool:
        """ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸"""
        try:
            response = self.client.table(table_name).select(column_name).limit(1).execute()
            return True
        except Exception:
            return False
    
    def _suggest_schema_creation(self, missing_tables: List[str]):
        """ìŠ¤í‚¤ë§ˆ ìƒì„± ì•ˆë‚´"""
        schema_file = Path('config/database_schema.sql')
        
        logger.error("=" * 50)
        logger.error("ğŸ“‹ ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± í•„ìš”")
        logger.error(f"ëˆ„ë½ëœ í…Œì´ë¸”: {', '.join(missing_tables)}")
        logger.error("")
        
        if schema_file.exists():
            logger.error("ğŸ”§ í•´ê²° ë°©ë²•:")
            logger.error("1. Supabase Dashboard â†’ SQL Editor ì´ë™")
            logger.error(f"2. {schema_file.absolute()} íŒŒì¼ ë‚´ìš© ë³µì‚¬")
            logger.error("3. SQL Editorì—ì„œ ì‹¤í–‰")
        else:
            logger.error("âš ï¸ database_schema.sql íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        logger.error("=" * 50)
    
    def _suggest_schema_update(self):
        """ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ ì•ˆë‚´"""
        logger.error("=" * 50)
        logger.error("ğŸ”„ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ í•„ìš”")
        logger.error("")
        logger.error("ë‹¤ìŒ SQLì„ Supabaseì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”:")
        logger.error("ALTER TABLE system_logs ADD COLUMN module_name VARCHAR(100);")
        logger.error("UPDATE system_logs SET module_name = 'unknown' WHERE module_name IS NULL;")
        logger.error("ALTER TABLE system_logs ALTER COLUMN module_name SET NOT NULL;")
        logger.error("=" * 50)
    
    def reconnect(self) -> bool:
        """Supabase í´ë¼ì´ì–¸íŠ¸ ì¬ì—°ê²°"""
        try:
            logger.info("Supabase ì¬ì—°ê²° ì‹œë„")
            
            # ìƒˆë¡œìš´ í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            self.client = create_client(self.url, self.key)
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            if self._test_connection():
                logger.info("Supabase ì¬ì—°ê²° ì„±ê³µ")
                return True
            else:
                logger.error("Supabase ì¬ì—°ê²° í›„ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"Supabase ì¬ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    # ===========================================
    # ë¡œê·¸ ê´€ë ¨ ë©”ì„œë“œ
    # ===========================================
    
    def save_log(self, module_name: str, level: str, message: str, 
                 trader_id: Optional[int] = None, data: Optional[Dict] = None) -> bool:
        """ì‹œìŠ¤í…œ ë¡œê·¸ ì €ì¥"""
        try:
            log_data = {
                'module_name': module_name,
                'level': level,
                'message': message,
                'trader_id': trader_id,
                'data': data,
                'created_at': self._datetime_to_string(datetime.now())
            }
            
            response = self.client.table('system_logs').insert(log_data).execute()
            return len(response.data) > 0
                
        except Exception as e:
            logger.error(f"ë¡œê·¸ ì €ì¥ ì¤‘ ì—ëŸ¬: {e}")
            return False
    
    # ===========================================
    # ì‹œì¥ ë°ì´í„° ê´€ë ¨ ë©”ì„œë“œ
    # ===========================================
    
    def save_market_data_batch(self, market_data_list: List[Dict]) -> bool:
        """
        ì‹œì¥ ë°ì´í„° ë°°ì¹˜ ì €ì¥ (ë””ë²„ê¹… ê°•í™” ë²„ì „)
        
        Args:
            market_data_list: ì‹œì¥ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            if not market_data_list:
                logger.warning("ì €ì¥í•  ì‹œì¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return True
            
            logger.info(f"[DEBUG] ë°°ì¹˜ ì €ì¥ ì‹œì‘: {len(market_data_list)}ê°œ")
            
            # ë°ì´í„° í˜•ì‹ ë³€í™˜ ë° datetime ì§ë ¬í™”
            processed_data = []
            for i, data in enumerate(market_data_list):
                try:
                    processed_row = {
                        'symbol': data['symbol'],
                        'timestamp': self._datetime_to_string(data['timestamp']),
                        'open': float(data['open']),
                        'high': float(data['high']),
                        'low': float(data['low']),
                        'close': float(data['close']),
                        'volume': float(data['volume'])
                    }
                    
                    # ì§€í‘œ ë°ì´í„° ì¶”ê°€ (ìˆëŠ” ê²½ìš°ë§Œ)
                    for key, value in data.items():
                        if key not in ['symbol', 'timestamp', 'open', 'high', 'low', 'close', 'volume']:
                            if value is not None:
                                processed_row[key] = float(value)
                    
                    processed_data.append(processed_row)
                    
                except Exception as e:
                    logger.error(f"[DEBUG] ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨ (ì¸ë±ìŠ¤ {i}): {e}")
                    logger.error(f"[DEBUG] ë¬¸ì œ ë°ì´í„°: {data}")
                    continue
            
            if not processed_data:
                logger.error("[DEBUG] ë³€í™˜ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            logger.info(f"[DEBUG] ë³€í™˜ ì™„ë£Œ: {len(processed_data)}ê°œ")
            logger.info(f"[DEBUG] ì²« ë²ˆì§¸ ë°ì´í„°: {processed_data[0]}")
            
            
            # Upsertë¡œ ë°°ì¹˜ ì €ì¥
            try:
                response = self.client.table('market_data').upsert(
                    processed_data,
                    on_conflict='symbol,timestamp'
                ).execute()
                
                success_count = len(response.data) if response.data else 0
                logger.info(f"[DEBUG] Supabase ì‘ë‹µ: {success_count}ê°œ ì €ì¥ë¨")
                
                if success_count != len(processed_data):
                    logger.warning(f"[DEBUG] ì €ì¥ ë¶ˆì¼ì¹˜: ìš”ì²­ {len(processed_data)}ê°œ, ì‹¤ì œ {success_count}ê°œ")
                    
                    # ì¼ë¶€ë§Œ ì €ì¥ëœ ê²½ìš° ì €ì¥ëœ ë°ì´í„° í™•ì¸
                    if response.data:
                        logger.info(f"[DEBUG] ì‹¤ì œ ì €ì¥ëœ ì²« ë²ˆì§¸: {response.data[0]}")
                        logger.info(f"[DEBUG] ì‹¤ì œ ì €ì¥ëœ ë§ˆì§€ë§‰: {response.data[-1]}")
                
                return success_count > 0
                
            except Exception as upsert_error:
                logger.error(f"[DEBUG] Upsert ì‹¤í–‰ ì‹¤íŒ¨: {upsert_error}")
                logger.error(f"[DEBUG] ë°ì´í„° íƒ€ì… í™•ì¸:")
                for key, value in processed_data[0].items():
                    logger.error(f"[DEBUG]   {key}: {type(value)} = {value}")
                return False
            
        except Exception as e:
            logger.error(f"[DEBUG] ë°°ì¹˜ ì €ì¥ ì „ì²´ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(f"[DEBUG] ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
            return False
    
    def save_market_data(self, symbol: str, timestamp: datetime, 
                        ohlcv: Dict, indicators: Optional[Dict] = None) -> bool:
        """ì‹œì¥ ë°ì´í„° ë‹¨ì¼ ì €ì¥"""
        try:
            data = {
                'symbol': symbol,
                'timestamp': timestamp,
                'open': ohlcv['open'],
                'high': ohlcv['high'],
                'low': ohlcv['low'],
                'close': ohlcv['close'],
                'volume': ohlcv['volume']
            }
            
            if indicators:
                data.update(indicators)
            
            return self.save_market_data_batch([data])
            
        except Exception as e:
            logger.error(f"ì‹œì¥ ë°ì´í„° ë‹¨ì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def save_market_data_with_retry(self, data_list: List[Dict]) -> bool:
        """ì‹œì¥ ë°ì´í„° ì €ì¥ (3ë‹¨ê³„ ì¬ì‹œë„)"""
        try:
            # 1ì°¨ ì‹œë„
            return self.save_market_data_batch(data_list)
            
        except Exception as e:
            logger.warning(f"ì‹œì¥ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨ (1ì°¨), ì¬ì‹œë„: {e}")
            
            try:
                # 2ì°¨ ì‹œë„
                return self.save_market_data_batch(data_list)
                
            except Exception as e2:
                logger.warning(f"ì‹œì¥ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨ (2ì°¨), ì¬ì—°ê²° í›„ ì‹œë„: {e2}")
                
                try:
                    # 3ì°¨ ì‹œë„: ì¬ì—°ê²° í›„ ì €ì¥
                    if self.reconnect():
                        return self.save_market_data_batch(data_list)
                    else:
                        raise Exception("ì¬ì—°ê²° ì‹¤íŒ¨")
                        
                except Exception as e3:
                    logger.error(f"ì‹œì¥ ë°ì´í„° ì €ì¥ ìµœì¢… ì‹¤íŒ¨: {e3}")
                    raise Exception(f"ì‹œì¥ ë°ì´í„° ì €ì¥ ìµœì¢… ì‹¤íŒ¨: {e3}")
    
    def get_latest_market_data(self, symbol: str, limit: int = 100) -> pd.DataFrame:
        """ìµœì‹  ì‹œì¥ ë°ì´í„° ì¡°íšŒ"""
        try:
            response = self.client.table('market_data').select('*').eq(
                'symbol', symbol
            ).order('timestamp', desc=True).limit(limit).execute()
            
            if response.data:
                df = pd.DataFrame(response.data)
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                df = df.sort_values('timestamp').reset_index(drop=True)
                return df
            else:
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"ì‹œì¥ ë°ì´í„° ì¡°íšŒ ì¤‘ ì—ëŸ¬: {e}")
            return pd.DataFrame()
    
    def get_missing_time_ranges(self, symbol: str, required_count: int = 200) -> List[tuple]:
        """ëˆ„ë½ëœ ì‹œê°„ êµ¬ê°„ íƒì§€"""
        try:
            # í˜„ì¬ ì‹œê°ì—ì„œ í•„ìš”í•œ ì‹œê°„ ë²”ìœ„ ê³„ì‚°
            now = datetime.now()
            current_minute = now.replace(second=0, microsecond=0)
            start_time = current_minute - timedelta(minutes=required_count - 1)
            
            logger.debug(f"{symbol} í•„ìš” ì‹œê°„ ë²”ìœ„: {start_time} ~ {current_minute}")
            
            # í•´ë‹¹ ì‹œê°„ ë²”ìœ„ì˜ ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ
            response = self.client.table('market_data').select(
                'timestamp'
            ).eq('symbol', symbol).gte(
                'timestamp', self._datetime_to_string(start_time)
            ).lte(
                'timestamp', self._datetime_to_string(current_minute)
            ).order('timestamp', desc=False).execute()
            
            existing_times = []
            if response.data:
                existing_times = [
                    datetime.fromisoformat(row['timestamp'].replace('Z', '+00:00')).replace(tzinfo=None)
                    for row in response.data
                ]
            
            # í•„ìš”í•œ ëª¨ë“  ì‹œê°„ ìƒì„±
            required_times = []
            current = start_time
            while current <= current_minute:
                required_times.append(current)
                current += timedelta(minutes=1)
            
            # ëˆ„ë½ëœ ì‹œê°„ ì°¾ê¸°
            existing_times_set = set(existing_times)
            missing_times = [t for t in required_times if t not in existing_times_set]
            
            if not missing_times:
                return []
            
            # ì—°ì†ëœ ëˆ„ë½ êµ¬ê°„ìœ¼ë¡œ ê·¸ë£¹í™”
            missing_ranges = []
            if missing_times:
                missing_times.sort()
                range_start = missing_times[0]
                range_end = missing_times[0]
                
                for i in range(1, len(missing_times)):
                    if missing_times[i] - missing_times[i-1] == timedelta(minutes=1):
                        range_end = missing_times[i]
                    else:
                        missing_ranges.append((range_start, range_end))
                        range_start = missing_times[i]
                        range_end = missing_times[i]
                
                # ë§ˆì§€ë§‰ êµ¬ê°„ ì¶”ê°€
                missing_ranges.append((range_start, range_end))
            
            logger.debug(f"{symbol} ëˆ„ë½ êµ¬ê°„ {len(missing_ranges)}ê°œ")
            return missing_ranges
            
        except Exception as e:
            logger.error(f"ëˆ„ë½ êµ¬ê°„ íƒì§€ ì¤‘ ì—ëŸ¬: {e}")
            # ì—ëŸ¬ì‹œ ì „ì²´ êµ¬ê°„ì„ ëˆ„ë½ìœ¼ë¡œ ì²˜ë¦¬
            now = datetime.now().replace(second=0, microsecond=0)
            start_time = now - timedelta(minutes=required_count - 1)
            return [(start_time, now)]
    
    def get_latest_candle_time(self, symbol: str) -> Optional[datetime]:
        """í•´ë‹¹ ì‹¬ë³¼ì˜ ê°€ì¥ ìµœê·¼ ìº”ë“¤ ì‹œê°„ ì¡°íšŒ"""
        try:
            response = self.client.table('market_data').select(
                'timestamp'
            ).eq('symbol', symbol).order(
                'timestamp', desc=True
            ).limit(1).execute()
            
            if response.data:
                timestamp_str = response.data[0]['timestamp']
                return datetime.fromisoformat(timestamp_str.replace('Z', '+00:00')).replace(tzinfo=None)
            
            return None
            
        except Exception as e:
            logger.error(f"ìµœê·¼ ìº”ë“¤ ì‹œê°„ ì¡°íšŒ ì¤‘ ì—ëŸ¬: {e}")
            return None

    def get_collection_strategy(self, symbol: str, required_count: int = 200) -> Dict:
        """
        ë°ì´í„° ìˆ˜ì§‘ ì „ëµ ë°˜í™˜ (ë””ë²„ê¹… ë²„ì „)
        
        Args:
            symbol: ê±°ë˜ ì‹¬ë³¼
            required_count: í•„ìš”í•œ ìº”ë“¤ ê°œìˆ˜
            
        Returns:
            ìˆ˜ì§‘ ì „ëµ ë”•ì…”ë„ˆë¦¬
        """
        try:
            now = datetime.now().replace(second=0, microsecond=0)
            target_start = now - timedelta(minutes=required_count - 1)
            
            logger.info(f"[DEBUG] {symbol} ì‹œê°„ ê³„ì‚°:")
            logger.info(f"[DEBUG] í˜„ì¬ ì‹œê°„: {now}")
            logger.info(f"[DEBUG] ëª©í‘œ ì‹œì‘: {target_start}")
            logger.info(f"[DEBUG] í•„ìš” ê°œìˆ˜: {required_count}")
            
            # ê¸°ì¡´ ë°ì´í„° ê°œìˆ˜ ë° ë²”ìœ„ í™•ì¸
            response = self.client.table('market_data').select(
                'timestamp'
            ).eq('symbol', symbol).gte(
                'timestamp', self._datetime_to_string(target_start)
            ).lte(
                'timestamp', self._datetime_to_string(now)
            ).order('timestamp').execute()
            
            existing_count = len(response.data) if response.data else 0
            logger.info(f"[DEBUG] {symbol} ê¸°ì¡´ ë°ì´í„°: {existing_count}ê°œ")
            
            # ì „ëµ ê²°ì •
            if existing_count == 0:
                # ì „ì²´ ìˆ˜ì§‘ í•„ìš”
                chunks = self._create_collection_chunks(target_start, required_count)
                logger.info(f"[DEBUG] {symbol} ì „ëµ: ì „ì²´ ìˆ˜ì§‘, ì²­í¬ {len(chunks)}ê°œ")
                
                # ì²« ë²ˆì§¸ ì²­í¬ ë¡œê¹…
                if chunks:
                    logger.info(f"[DEBUG] ì²« ë²ˆì§¸ ì²­í¬: {chunks[0]}")
                
                return {
                    'strategy': 'bulk_collect',
                    'total_needed': required_count,
                    'chunks': chunks,
                    'existing_count': 0
                }
            
            elif existing_count >= required_count * 0.95:  # 95% ì´ìƒ ìˆìœ¼ë©´
                # ìµœì‹  ë°ì´í„°ë§Œ ë³´ì™„
                latest_time = datetime.fromisoformat(
                    response.data[-1]['timestamp'].replace('Z', '+00:00')
                ).replace(tzinfo=None)
                
                minutes_gap = int((now - latest_time).total_seconds() / 60)
                
                logger.info(f"[DEBUG] {symbol} ìµœì‹  ì‹œê°„: {latest_time}, ê°­: {minutes_gap}ë¶„")
                
                if minutes_gap <= 10:  # 10ë¶„ ì´ë‚´ë©´ ìµœì‹  ìƒíƒœ
                    return {
                        'strategy': 'up_to_date',
                        'total_needed': 0,
                        'chunks': [],
                        'existing_count': existing_count
                    }
                else:
                    chunks = [{'start_time': latest_time + timedelta(minutes=1), 'count': minutes_gap}]
                    logger.info(f"[DEBUG] {symbol} ê°­ ë³´ì™„: {chunks}")
                    
                    return {
                        'strategy': 'fill_gaps',
                        'total_needed': minutes_gap,
                        'chunks': chunks,
                        'existing_count': existing_count
                    }
            
            else:
                # ë¶€ë¶„ì  ë³´ì™„
                needed = required_count - existing_count
                chunks = self._create_collection_chunks(target_start, needed)
                
                logger.info(f"[DEBUG] {symbol} ë¶€ë¶„ ë³´ì™„: {needed}ê°œ í•„ìš”, ì²­í¬ {len(chunks)}ê°œ")
                if chunks:
                    logger.info(f"[DEBUG] ì²« ë²ˆì§¸ ì²­í¬: {chunks[0]}")
                
                return {
                    'strategy': 'fill_gaps',
                    'total_needed': needed,
                    'chunks': chunks,
                    'existing_count': existing_count
                }
                
        except Exception as e:
            logger.error(f"[DEBUG] ìˆ˜ì§‘ ì „ëµ ìƒì„± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ì‹œ ì „ì²´ ìˆ˜ì§‘ ì „ëµ ë°˜í™˜
            now_fallback = datetime.now()
            target_start_fallback = now_fallback - timedelta(minutes=required_count)
            
            return {
                'strategy': 'bulk_collect',
                'total_needed': required_count,
                'chunks': self._create_collection_chunks(target_start_fallback, required_count),
                'existing_count': 0
            }
    
    def _create_collection_chunks(self, start_time: datetime, total_count: int) -> List[Dict]:
        """
        ìˆ˜ì§‘ ì²­í¬ ìƒì„± (1000ê°œì”© ë¶„í• )
        
        Args:
            start_time: ì‹œì‘ ì‹œê°„
            total_count: ì´ í•„ìš” ê°œìˆ˜
            
        Returns:
            [{'start_time': datetime, 'count': int}] ë¦¬ìŠ¤íŠ¸
        """
        chunks = []
        current_start = start_time
        remaining = total_count
        
        while remaining > 0:
            chunk_size = min(remaining, 1000)  # ë°”ì´ë‚¸ìŠ¤ ì œí•œ
            
            chunks.append({
                'start_time': current_start,
                'count': chunk_size
            })
            
            current_start += timedelta(minutes=chunk_size)
            remaining -= chunk_size
        
        logger.debug(f"ìˆ˜ì§‘ ì²­í¬ ìƒì„±: {len(chunks)}ê°œ ì²­í¬, ì´ {total_count}ê°œ")
        return chunks
    
    def get_latest_timestamp(self, symbol: str) -> Optional[datetime]:
        """
        í•´ë‹¹ ì‹¬ë³¼ì˜ ìµœì‹  íƒ€ì„ìŠ¤íƒ¬í”„ ì¡°íšŒ (ê°„ë‹¨ ë²„ì „)
        
        Args:
            symbol: ê±°ë˜ ì‹¬ë³¼
            
        Returns:
            ìµœì‹  íƒ€ì„ìŠ¤íƒ¬í”„ ë˜ëŠ” None
        """
        try:
            response = self.client.table('market_data').select(
                'timestamp'
            ).eq('symbol', symbol).order(
                'timestamp', desc=True
            ).limit(1).execute()
            
            if response.data:
                return datetime.fromisoformat(
                    response.data[0]['timestamp'].replace('Z', '+00:00')
                ).replace(tzinfo=None)
            
            return None
            
        except Exception as e:
            logger.error(f"ìµœì‹  íƒ€ì„ìŠ¤íƒ¬í”„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    # ===========================================
    # ê±°ë˜ ë° íŠ¸ë ˆì´ë” ê´€ë ¨ ë©”ì„œë“œ
    # ===========================================
    
    def save_trade(self, trader_id: int, trade_data: Dict) -> bool:
        """ê±°ë˜ ë‚´ì—­ ì €ì¥"""
        try:
            trade_record = {
                'trader_id': trader_id,
                **trade_data,
                'created_at': self._datetime_to_string(datetime.now())
            }
            
            # executed_atì´ datetime ê°ì²´ì¸ ê²½ìš° ë³€í™˜
            if 'executed_at' in trade_record and isinstance(trade_record['executed_at'], datetime):
                trade_record['executed_at'] = self._datetime_to_string(trade_record['executed_at'])
            
            response = self.client.table('trades').insert(trade_record).execute()
            return len(response.data) > 0
            
        except Exception as e:
            logger.error(f"ê±°ë˜ ë‚´ì—­ ì €ì¥ ì¤‘ ì—ëŸ¬: {e}")
            return False
    
    def update_trader_pnl(self, trader_id: int, total_pnl: float) -> bool:
        """íŠ¸ë ˆì´ë” ì´ ì†ìµ ì—…ë°ì´íŠ¸"""
        try:
            response = self.client.table('traders').update({
                'total_pnl': total_pnl,
                'updated_at': self._datetime_to_string(datetime.now())
            }).eq('id', trader_id).execute()
            
            return len(response.data) > 0
            
        except Exception as e:
            logger.error(f"íŠ¸ë ˆì´ë” PnL ì—…ë°ì´íŠ¸ ì¤‘ ì—ëŸ¬: {e}")
            return False
    
    def get_trader_info(self, trader_id: int) -> Optional[Dict]:
        """íŠ¸ë ˆì´ë” ì •ë³´ ì¡°íšŒ"""
        try:
            response = self.client.table('traders').select('*').eq(
                'id', trader_id
            ).single().execute()
            
            return response.data if response.data else None
            
        except Exception as e:
            logger.error(f"íŠ¸ë ˆì´ë” ì •ë³´ ì¡°íšŒ ì¤‘ ì—ëŸ¬: {e}")
            return None
    
    def get_active_traders(self) -> List[Dict]:
        """í™œì„±í™”ëœ íŠ¸ë ˆì´ë” ëª©ë¡ ì¡°íšŒ"""
        try:
            response = self.client.table('traders').select('*').eq(
                'is_active', True
            ).execute()
            
            return response.data or []
            
        except Exception as e:
            logger.error(f"í™œì„± íŠ¸ë ˆì´ë” ì¡°íšŒ ì¤‘ ì—ëŸ¬: {e}")
            return []
    
    # ===========================================
    # ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œ
    # ===========================================
    
    def get_database_info(self) -> Dict:
        """ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ì¡°íšŒ (ë””ë²„ê¹…ìš©)"""
        info = {
            'connection': False,
            'tables': {},
            'total_records': 0
        }
        
        try:
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            info['connection'] = self._test_connection()
            
            # ê° í…Œì´ë¸” ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ
            tables = ['strategies', 'traders', 'positions', 'trades', 'market_data', 'system_logs']
            total_records = 0
            
            for table in tables:
                try:
                    response = self.client.table(table).select('id', count='exact').execute()
                    count = response.count or 0
                    info['tables'][table] = {
                        'exists': True,
                        'records': count
                    }
                    total_records += count
                except Exception:
                    info['tables'][table] = {
                        'exists': False,
                        'records': 0
                    }
            
            info['total_records'] = total_records
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return info